{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1840101c",
   "metadata": {},
   "source": [
    "### Advanced Models for ETTh1 Forecasting Benchmark\n",
    "\n",
    "This example demonstrates advanced forecasting models applied to the ETTh1 (Electricity Transformer Temperature, Hourly) benchmark, a widely adopted standard in the forecasting community. The ETTh1 dataset presents significant challenges with its high-frequency electricity transformer measurements, capturing complex temporal dynamics including daily and seasonal cycles, alongside irregular fluctuations that test state-of-the-art forecasting capabilities.\n",
    "\n",
    "To ensure computational efficiency in this notebook, we use a subset of 1,000 rows and reduced `forecasting_horizon` and `observation_length` parameters compared to standard benchmark configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00050d3",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e2cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(pathlib.Path().resolve().parent.as_posix())\n",
    "\n",
    "from inait import predict_test, score_test, plot, load_credentials\n",
    "\n",
    "base_url, auth_key = load_credentials(\"../credentials.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3462112b",
   "metadata": {},
   "source": [
    "### Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/etth1_small.csv\"\n",
    "data = pd.read_csv(data_path, index_col=0)\n",
    "\n",
    "# Configure prediction parameters\n",
    "target_columns = data.columns.tolist()  # Use all columns as targets\n",
    "\n",
    "forecasting_horizon = 12\n",
    "observation_length = 24\n",
    "\n",
    "test_size = 5  # we will evaluate the model performances on the last 5 steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feea1e14",
   "metadata": {},
   "source": [
    "### Split the data into train/test \n",
    "\n",
    "The ETTh1 dataset contains hourly electricity transformer measurements across 7 variables, including electricity loads and temperatures. Our goal is to predict all 7 variables simultaneously for the next 12 hours using three progressively sophisticated models: `Inait-basic`, `Inait-advanced`, and `Inait-best`. Note that higher-performing models require longer computation times.\n",
    "\n",
    "Model evaluation follows standard machine learning practices: we reserve a portion of the dataset as a test set for performance assessment, while using the remaining data for training. The test set remains unseen during training to provide an unbiased evaluation. We measure performance using Mean Absolute Error (MAE); lower MAE indicates better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c6613",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "predictions = []\n",
    "for model in [\"Inait-basic\", \"Inait-advanced\", \"Inait-best\"]:\n",
    "    prediction = predict_test(\n",
    "        base_url=base_url,\n",
    "        auth_key=auth_key,\n",
    "        data=data,\n",
    "        target_columns=target_columns,\n",
    "        forecasting_horizon=forecasting_horizon,\n",
    "        observation_length=observation_length,\n",
    "        model=model,\n",
    "        test_size=test_size,\n",
    "    )[\"predictions\"]\n",
    "    predictions.append(prediction)\n",
    "    scores.append(score_test(predictions=prediction, ground_truth=data, metric=\"mae\"))\n",
    "    time.sleep(1)\n",
    "\n",
    "pd.DataFrame(\n",
    "    scores, columns=[\"MAE\"], index=[\"Inait basic\", \"Inait advanced\", \"Inait best\"]\n",
    ").round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0fba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {\n",
    "    \"Inait-basic\": predictions[0][-1],\n",
    "    \"Inait-advanced\": predictions[1][-1],\n",
    "    \"Inait-best\": predictions[2][-1],\n",
    "}\n",
    "\n",
    "plot(\n",
    "    historical_data=data,\n",
    "    predicted_data=predictions,\n",
    "    # legend_title_predicted=\"Inait-best prediction\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf4ef2d",
   "metadata": {},
   "source": [
    "### Results Analysis\n",
    "\n",
    "The models successfully capture the ground truth patterns for most variables, demonstrating strong forecasting performance. While some variables show larger prediction errors, it's important to note that this is a simplified simulation optimized for notebook execution time.\n",
    "\n",
    "Running the full benchmark configuration would yield the comprehensive results shown in the following comparison plot against state-of-the-art pretrained models from leading competitors.\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"../assets/benchmark_comparison_etth1_inait.png\" alt=\"Benchmark comparison results\" style=\"width: 60%;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d28a02",
   "metadata": {},
   "source": [
    "### Comparison Against Open-Source Baseline Models\n",
    "\n",
    "To provide context for our results, we'll compare the Inait models against traditional forecasting baselines implemented using open-source libraries. We evaluate two common baseline approaches: a naive model (which simply repeats the last observed values) and a linear regression model. While these tools are freely available, implementing them effectively still requires significant forecasting and data science expertise, as you will see in the multiple lines of code in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f54202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "\n",
    "class NaiveBaseline(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"Naive baseline that predicts the last observed value\"\"\"\n",
    "\n",
    "    def __init__(self, strategy=\"last\"):\n",
    "        self.strategy = strategy\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # For naive baseline, we don't need to fit anything\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.strategy == \"last\":\n",
    "            # Use the last observation_length values to predict\n",
    "            # X shape: (n_samples, obs_len * n_features)\n",
    "            # Extract last value for each feature and repeat for horizon\n",
    "            n_samples, n_features_flat = X.shape\n",
    "            n_features = len(target_columns)  # Assuming target_columns is available\n",
    "            obs_len = n_features_flat // n_features\n",
    "\n",
    "            # Reshape X to (n_samples, obs_len, n_features)\n",
    "            X_reshaped = X.reshape(n_samples, obs_len, n_features)\n",
    "\n",
    "            # Take last observation and repeat for forecasting horizon\n",
    "            last_obs = X_reshaped[:, -1, :]  # Shape: (n_samples, n_features)\n",
    "\n",
    "            # Repeat for forecasting horizon and flatten\n",
    "            predictions = np.tile(last_obs, (1, forecasting_horizon))\n",
    "\n",
    "            return predictions\n",
    "\n",
    "        return np.zeros((X.shape[0], X.shape[1]))  # Fallback\n",
    "\n",
    "\n",
    "def predict_sklearn(\n",
    "    data,\n",
    "    target_columns,\n",
    "    forecasting_horizon,\n",
    "    observation_length,\n",
    "    estimator=None,\n",
    "    train_size=None,\n",
    "    test_size=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Forecast using sklearn estimators with column-wise window standardization\n",
    "    \"\"\"\n",
    "    if estimator == \"naive\":\n",
    "        estimator = NaiveBaseline()\n",
    "    else:\n",
    "        estimator = LinearRegression()\n",
    "\n",
    "    if train_size is not None and test_size is not None:\n",
    "        raise ValueError(\n",
    "            \"Both train_size and test_size cannot be specified at the same time. Please specify only one of them.\"\n",
    "        )\n",
    "    if train_size is not None:\n",
    "        split_idx = int(len(data) * train_size)\n",
    "    elif test_size is not None:\n",
    "        split_idx = len(data) - test_size - forecasting_horizon\n",
    "    else:\n",
    "        split_idx = int(len(data) * 0.8)\n",
    "\n",
    "    train_data = data.iloc[:split_idx]\n",
    "\n",
    "    # Create sequences from training data with column-wise standardization\n",
    "    def create_sequences(data, obs_len, horizon):\n",
    "        X, y = [], []\n",
    "        eps = 1e-8  # Small value to avoid division by zero\n",
    "\n",
    "        for i in range(len(data) - obs_len - horizon + 1):\n",
    "            # Get observation window\n",
    "            window = data.iloc[i : i + obs_len].values\n",
    "\n",
    "            # Column-wise standardization for this window\n",
    "            mu = window.mean(axis=0)\n",
    "            sigma = window.std(axis=0)\n",
    "            sigma[sigma < eps] = 1.0  # Avoid division by zero\n",
    "\n",
    "            # Standardize the window\n",
    "            norm_window = (window - mu) / sigma\n",
    "\n",
    "            X.append(norm_window.flatten())\n",
    "            y.append(data.iloc[i + obs_len : i + obs_len + horizon].values)\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    # Train model on training sequences only\n",
    "    X_train, y_train = create_sequences(\n",
    "        train_data[target_columns], observation_length, forecasting_horizon\n",
    "    )\n",
    "    y_train_flat = y_train.reshape(y_train.shape[0], -1)\n",
    "\n",
    "    # Fit model\n",
    "    if isinstance(estimator, NaiveBaseline):\n",
    "        model = estimator\n",
    "        model.fit(X_train, y_train_flat)\n",
    "    else:\n",
    "        model = MultiOutputRegressor(estimator)\n",
    "        model.fit(X_train, y_train_flat)\n",
    "\n",
    "    # Generate predictions for test period\n",
    "    predictions = []\n",
    "    start_test_idx = split_idx\n",
    "    eps = 1e-8\n",
    "\n",
    "    for t in range(start_test_idx, len(data) - forecasting_horizon):\n",
    "        # Get test window and standardize it independently\n",
    "        test_window = data.iloc[t - observation_length : t].values\n",
    "\n",
    "        # Column-wise standardization for this test window\n",
    "        mu = test_window.mean(axis=0)\n",
    "        sigma = test_window.std(axis=0)\n",
    "        sigma[sigma < eps] = 1.0  # Avoid division by zero\n",
    "\n",
    "        # Standardize the test window\n",
    "        norm_test_window = (test_window - mu) / sigma\n",
    "        X_test = norm_test_window.flatten().reshape(1, -1)\n",
    "\n",
    "        y_pred_flat = model.predict(X_test)\n",
    "        y_pred = y_pred_flat.reshape(forecasting_horizon, len(target_columns))\n",
    "\n",
    "        # Create prediction DataFrame\n",
    "        pred_df = pd.DataFrame(\n",
    "            y_pred,\n",
    "            columns=target_columns,\n",
    "            index=data.index[t : t + forecasting_horizon],\n",
    "        )\n",
    "        predictions.append(pred_df)\n",
    "\n",
    "    estimator_name = (\n",
    "        \"naive\" if isinstance(estimator, NaiveBaseline) else type(estimator).__name__\n",
    "    )\n",
    "    session_ids = [f\"{estimator_name}_session_{i}\" for i in range(len(predictions))]\n",
    "\n",
    "    return predictions, session_ids\n",
    "\n",
    "\n",
    "# Naive Baseline\n",
    "naive_predictions, naive_sessions = predict_sklearn(\n",
    "    data=data,\n",
    "    target_columns=target_columns,\n",
    "    forecasting_horizon=forecasting_horizon,\n",
    "    observation_length=observation_length,\n",
    "    estimator=\"naive\",\n",
    "    test_size=test_size,\n",
    ")\n",
    "\n",
    "\n",
    "# Linear Regression\n",
    "linear_predictions, linear_sessions = predict_sklearn(\n",
    "    data=data,\n",
    "    target_columns=target_columns,\n",
    "    forecasting_horizon=forecasting_horizon,\n",
    "    observation_length=observation_length,\n",
    "    estimator=LinearRegression(),\n",
    "    test_size=test_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ddac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(\n",
    "    scores, columns=[\"MAE\"], index=[\"Inait basic\", \"Inait advanced\", \"Inait best\"]\n",
    ").round(4)\n",
    "\n",
    "scores_df = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(\n",
    "            score_test(predictions=naive_predictions, ground_truth=data, metric=\"mae\"),\n",
    "            columns=[\"MAE\"],\n",
    "            index=[\"Naive from scratch\"],\n",
    "        ),\n",
    "        pd.DataFrame(\n",
    "            score_test(predictions=linear_predictions, ground_truth=data, metric=\"mae\"),\n",
    "            columns=[\"MAE\"],\n",
    "            index=[\"Linear from scratch\"],\n",
    "        ),\n",
    "        scores_df,\n",
    "    ], axis=0\n",
    ").round(4)\n",
    "scores_df.columns = [\"Mean Absolute Error (lower is better)\"]\n",
    "print(scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a712f122",
   "metadata": {},
   "source": [
    "### Performance Comparison Visualization\n",
    "\n",
    "The following chart compares our Inait models against the open-source baseline implementations. For clarity of visualization, we exclude the Naive model from this comparison due to its significantly higher error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df97931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "scores_df = scores_df.drop(index=[\"Naive from scratch\"])\n",
    "\n",
    "# Create vertical bar plot with green color scale based on values\n",
    "fig = px.bar(\n",
    "    scores_df,\n",
    "    x=scores_df.index,\n",
    "    y=\"Mean Absolute Error (lower is better)\",\n",
    "    color=\"Mean Absolute Error (lower is better)\",\n",
    "    color_continuous_scale=\"Greens_r\",  # Reversed greens (darker for lower values)\n",
    "    title=\"Model Performance Comparison\",\n",
    "    labels={\"x\": \"Models\", \"y\": \"Mean Absolute Error (lower is better)\"},\n",
    "    text=\"Mean Absolute Error (lower is better)\",  # Add values on bars\n",
    ")\n",
    "\n",
    "# Update layout for better readability\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Models\",\n",
    "    yaxis_title=\"Mean Absolute Error (lower is better)\",\n",
    "    showlegend=False,\n",
    "    yaxis=dict(\n",
    "        range=[\n",
    "            scores_df[\"Mean Absolute Error (lower is better)\"].min() * 0.9,\n",
    "            scores_df[\"Mean Absolute Error (lower is better)\"].max() * 1.1,\n",
    "        ]\n",
    "    ),\n",
    "    coloraxis_showscale=False,\n",
    ")\n",
    "\n",
    "fig.update_traces(texttemplate=\"%{text:.4f}\", textposition=\"outside\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f5d507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inait-predict-examples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
