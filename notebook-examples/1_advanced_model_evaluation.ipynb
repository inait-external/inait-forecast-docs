{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1840101c",
   "metadata": {},
   "source": [
    "### Advanced Models for ETTh1 Forecasting Benchmark\n",
    "\n",
    "This example demonstrates advanced forecasting models applied to the ETTh1 (Electricity Transformer Temperature, Hourly) benchmark, a widely adopted standard in the forecasting community. The ETTh1 dataset presents significant challenges with its high-frequency electricity transformer measurements, capturing complex temporal dynamics including daily and seasonal cycles, alongside irregular fluctuations that test state-of-the-art forecasting capabilities.\n",
    "\n",
    "To ensure computational efficiency in this notebook, we use a subset of 1,000 rows and reduced `forecasting_horizon` and `observation_length` parameters compared to standard benchmark configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00050d3",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e2cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.append(pathlib.Path().resolve().parent.as_posix())\n",
    "\n",
    "from inait import predict_test, score_test, plot, load_credentials\n",
    "\n",
    "base_url, auth_key = load_credentials(\"../credentials.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feea1e14",
   "metadata": {},
   "source": [
    "### Load the data and split it into train/test \n",
    "\n",
    "The ETTh1 dataset (source: Zhou, Haoyi, et al. [\"Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting\"](https://arxiv.org/pdf/2012.07436), 2021) contains hourly electricity transformer measurements across 7 variables, including electricity loads and temperatures. Our goal is to predict all 7 variables simultaneously for the next 12 hours using three progressively sophisticated models: `Inait-basic`, `Inait-advanced`, and `Inait-best`. Note that higher-performing models require longer computation times. \n",
    "\n",
    "Model evaluation follows standard machine learning practices: we reserve a portion of the dataset as a test set for performance assessment, while using the remaining data for training. The test set remains unseen during training to provide an unbiased evaluation. We measure performance using Mean Absolute Error (MAE); lower MAE indicates better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/etth1_small.csv\"\n",
    "data = pd.read_csv(data_path, index_col=0)\n",
    "data = data[sorted(data.columns)]\n",
    "plot(historical_data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15b55cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure prediction parameters\n",
    "target_columns = data.columns.tolist()  # Use all columns as targets\n",
    "\n",
    "forecasting_horizon = 12  # Predict 12 hours ahead\n",
    "observation_length = 24  # Use last 24 hours as historical context\n",
    "\n",
    "test_size = 5  # we will evaluate the model performances on the last 5 steps\n",
    "\n",
    "models = [\"inait-basic\", \"inait-advanced\", \"inait-best\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502db362",
   "metadata": {},
   "source": [
    "**Note:** The next cell may take a few minutes to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c6613",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, predictions = {}, {}\n",
    "for model in tqdm(models, leave=True, postfix=f\"Evaluating models {', '.join(models)}\"):\n",
    "    prediction = predict_test(\n",
    "        base_url=base_url,\n",
    "        auth_key=auth_key,\n",
    "        data=data,\n",
    "        target_columns=target_columns,\n",
    "        forecasting_horizon=forecasting_horizon,\n",
    "        observation_length=observation_length,\n",
    "        model=model,\n",
    "        test_size=test_size,\n",
    "    )[\"predictions\"]\n",
    "    predictions[model] = prediction\n",
    "    scores[model] = score_test(predictions=prediction, ground_truth=data, metric=\"mae\")\n",
    "    time.sleep(1)\n",
    "\n",
    "scores_df = pd.DataFrame.from_dict(scores, orient=\"index\", columns=[\"MAE\"])\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d28a02",
   "metadata": {},
   "source": [
    "### Comparison against open-source baseline models\n",
    "\n",
    "From the Mean Absolute Error of the three models shown above, we can already see that more complex approaches tend to yield better results.\n",
    "\n",
    "To put our results into perspective, we compare the inait models against traditional forecasting baselines implemented with open-source libraries. We evaluate two common baselines:\n",
    "- Seasonal Naive model; simply repeats the last observed window.\n",
    "- Linear regression model; fits a linear relationship to past observations.\n",
    "\n",
    "While these tools are freely available, implementing them effectively still requires solid forecasting and data science expertise as youâ€™ll notice from the multiple lines of code in the next cell.\n",
    "\n",
    "**Note:** These notebooks are designed to run in seconds. The delay you're seeing with the scikit-learn model is simply due to the shared MyBinder server we're using for this zero-setup demo. For comparison, our tests on a laptop and in GitHub Codespaces show a runtime of less than 5 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f54202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "\n",
    "class SeasonalNaiveBaseline(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"Seasonal Naive baseline that repeats the last forecasting_horizon observed values\"\"\"\n",
    "\n",
    "    def __init__(self, strategy=\"last\"):\n",
    "        self.strategy = strategy\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # For naive baseline, we don't need to fit anything\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.strategy == \"last\":\n",
    "            # X shape: (n_samples, obs_len * n_features)\n",
    "            n_samples, n_features_flat = X.shape\n",
    "            n_features = len(target_columns)  # Assuming target_columns is available\n",
    "            obs_len = n_features_flat // n_features\n",
    "\n",
    "            # Reshape X to (n_samples, obs_len, n_features)\n",
    "            X_reshaped = X.reshape(n_samples, obs_len, n_features)\n",
    "\n",
    "            # Take the last forecasting_horizon observations for each sample\n",
    "            last_obs = X_reshaped[\n",
    "                :, -forecasting_horizon:, :\n",
    "            ]  # (n_samples, forecasting_horizon, n_features)\n",
    "\n",
    "            # Flatten to (n_samples, forecasting_horizon * n_features)\n",
    "            predictions = last_obs.reshape(n_samples, forecasting_horizon * n_features)\n",
    "\n",
    "            return predictions\n",
    "\n",
    "        return np.zeros((X.shape[0], X.shape[1]))  # Fallback\n",
    "\n",
    "\n",
    "def predict_sklearn(\n",
    "    data,\n",
    "    target_columns,\n",
    "    forecasting_horizon,\n",
    "    observation_length,\n",
    "    estimator=None,\n",
    "    train_size=None,\n",
    "    test_size=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Forecast using sklearn estimators with column-wise window standardization\n",
    "    \"\"\"\n",
    "    if estimator == \"naive\":\n",
    "        estimator = SeasonalNaiveBaseline()\n",
    "    else:\n",
    "        estimator = LinearRegression(tol=0.001)\n",
    "\n",
    "    if train_size is not None and test_size is not None:\n",
    "        raise ValueError(\n",
    "            \"Both train_size and test_size cannot be specified at the same time. Please specify only one of them.\"\n",
    "        )\n",
    "    if train_size is not None:\n",
    "        split_idx = int(len(data) * train_size)\n",
    "    elif test_size is not None:\n",
    "        split_idx = len(data) - test_size - forecasting_horizon\n",
    "    else:\n",
    "        train_size = 0.8  # Default to 80% training data\n",
    "        split_idx = int(len(data) * train_size)\n",
    "\n",
    "    train_data = data.iloc[:split_idx]\n",
    "\n",
    "    # Create sequences from training data with column-wise standardization\n",
    "    def create_sequences(data, obs_len, horizon):\n",
    "        X, y = [], []\n",
    "\n",
    "        for i in range(len(data) - obs_len - horizon + 1):\n",
    "            # Get observation window\n",
    "            window = data.iloc[i : i + obs_len].values\n",
    "\n",
    "            X.append(window.flatten())\n",
    "            y.append(data.iloc[i + obs_len : i + obs_len + horizon].values)\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    # Train model on training sequences only\n",
    "    X_train, y_train = create_sequences(\n",
    "        train_data[target_columns], observation_length, forecasting_horizon\n",
    "    )\n",
    "    y_train_flat = y_train.reshape(y_train.shape[0], -1)\n",
    "\n",
    "    # Fit model\n",
    "    if isinstance(estimator, SeasonalNaiveBaseline):\n",
    "        model = estimator\n",
    "        model.fit(X_train, y_train_flat)\n",
    "    else:\n",
    "        model = MultiOutputRegressor(estimator)\n",
    "        model.fit(X_train, y_train_flat)\n",
    "\n",
    "    # Generate predictions for test period\n",
    "    predictions = []\n",
    "    start_test_idx = split_idx\n",
    "\n",
    "    for t in tqdm(range(start_test_idx + 1, len(data) - forecasting_horizon + 1)):\n",
    "        # Get test window\n",
    "        test_window = data.iloc[t - observation_length : t].values\n",
    "\n",
    "        X_test = test_window.flatten().reshape(1, -1)\n",
    "\n",
    "        y_pred_flat = model.predict(X_test)\n",
    "        y_pred = y_pred_flat.reshape(forecasting_horizon, len(target_columns))\n",
    "\n",
    "        # Create prediction DataFrame\n",
    "        pred_df = pd.DataFrame(\n",
    "            y_pred,\n",
    "            columns=target_columns,\n",
    "            index=data.index[t : t + forecasting_horizon],\n",
    "        )\n",
    "        predictions.append(pred_df)\n",
    "\n",
    "    estimator_name = (\n",
    "        \"seasonal_naive\"\n",
    "        if isinstance(estimator, SeasonalNaiveBaseline)\n",
    "        else type(estimator).__name__\n",
    "    )\n",
    "    session_ids = [f\"{estimator_name}_session_{i}\" for i in range(len(predictions))]\n",
    "\n",
    "    return predictions, session_ids\n",
    "\n",
    "\n",
    "# Seasonal Naive Baseline\n",
    "print(\"Running sklearn for Seasonal Naive model...\")\n",
    "naive_predictions, naive_sessions = predict_sklearn(\n",
    "    data=data,\n",
    "    target_columns=target_columns,\n",
    "    forecasting_horizon=forecasting_horizon,\n",
    "    observation_length=observation_length,\n",
    "    estimator=\"naive\",\n",
    "    test_size=test_size,\n",
    ")\n",
    "\n",
    "\n",
    "# Linear Regression\n",
    "print(\"Running sklearn for Linear model...\")\n",
    "linear_predictions, linear_sessions = predict_sklearn(\n",
    "    data=data,\n",
    "    target_columns=target_columns,\n",
    "    forecasting_horizon=forecasting_horizon,\n",
    "    observation_length=observation_length,\n",
    "    estimator=LinearRegression(),\n",
    "    test_size=test_size,\n",
    ")\n",
    "\n",
    "# Concatenate predictions and scores into a single DataFrame to match the format of inait predictions\n",
    "predictions[\"Seasonal Naive from scratch\"] = [\n",
    "    df.add_suffix(\"_predicted\") for df in naive_predictions\n",
    "]\n",
    "predictions[\"Linear from scratch\"] = [\n",
    "    df.add_suffix(\"_predicted\") for df in linear_predictions\n",
    "]\n",
    "\n",
    "scores_df = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(\n",
    "            score_test(predictions=naive_predictions, ground_truth=data, metric=\"mae\"),\n",
    "            columns=[\"MAE\"],\n",
    "            index=[\"Seasonal Naive from scratch\"],\n",
    "        ),\n",
    "        pd.DataFrame(\n",
    "            score_test(predictions=linear_predictions, ground_truth=data, metric=\"mae\"),\n",
    "            columns=[\"MAE\"],\n",
    "            index=[\"Linear from scratch\"],\n",
    "        ),\n",
    "        scores_df,\n",
    "    ],\n",
    "    axis=0,\n",
    ").round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a712f122",
   "metadata": {},
   "source": [
    "### Performance comparison visualization\n",
    "\n",
    "The plot below compares the inait models with open-source baseline implementations. For clarity, we show only the last prediction for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff6236",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    historical_data=data.loc[\n",
    "        : predictions[models[0]][-1].index[-1], :\n",
    "    ],  # Show all historical data up to the last prediction\n",
    "    predicted_data={\n",
    "        key: values[-1] for key, values in predictions.items()\n",
    "    },  # Get the last test set for each model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5561ffc5",
   "metadata": {},
   "source": [
    "Let us now look at performances in terms of Mean Absolute Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df97931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Create vertical bar plot with green color scale based on values\n",
    "fig = px.bar(\n",
    "    scores_df,\n",
    "    x=scores_df.index,\n",
    "    y=\"MAE\",\n",
    "    color=\"MAE\",\n",
    "    color_continuous_scale=\"Greens_r\",  # Reversed greens (darker for lower values)\n",
    "    title=\"Model Performance Comparison\",\n",
    "    labels={\"x\": \"Models\", \"y\": \"MAE\"},\n",
    "    text=\"MAE\",  # Add values on bars\n",
    ")\n",
    "\n",
    "# Update layout for better readability\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Models\",\n",
    "    yaxis_title=\"MAE (lower is better)\",\n",
    "    showlegend=False,\n",
    "    yaxis=dict(\n",
    "        range=[\n",
    "            scores_df[\"MAE\"].min() * 0.9,\n",
    "            scores_df[\"MAE\"].max() * 1.1,\n",
    "        ]\n",
    "    ),\n",
    "    coloraxis_showscale=False,\n",
    ")\n",
    "\n",
    "fig.update_traces(texttemplate=\"%{text:.4f}\", textposition=\"outside\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f87b1",
   "metadata": {},
   "source": [
    "### Comments on results\n",
    "\n",
    "The models successfully capture the ground truth patterns for most variables, demonstrating strong forecasting performance. While some variables show larger prediction errors, it's important to note that this is a simplified simulation optimized for notebook execution time.\n",
    "\n",
    "Running the full benchmark configuration would yield the comprehensive results shown in the following comparison plot against state-of-the-art pretrained models from leading competitors.\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"../assets/benchmark_etth1_inait.png\" alt=\"Benchmark comparison results\" style=\"width: 60%;\">\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inait-predict-examples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
